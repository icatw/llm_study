#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Day 1: EmbeddingåŸºç¡€å®æˆ˜
å­¦ä¹ ç›®æ ‡ï¼š
1. ç†è§£æ–‡æœ¬å‘é‡åŒ–çš„åŸºæœ¬æ¦‚å¿µ
2. æŒæ¡é€šä¹‰åƒé—®APIçš„embeddingè°ƒç”¨
3. å®ç°æ–‡æœ¬ç›¸ä¼¼åº¦è®¡ç®—
4. å®Œæˆç®€å•çš„è¯­ä¹‰æœç´¢

é¢„è®¡ç”¨æ—¶ï¼š30åˆ†é’Ÿ
"""

import os
import numpy as np
from typing import List, Tuple
from dotenv import load_dotenv

# å°è¯•å¯¼å…¥dashscopeï¼Œå¦‚æœå¤±è´¥åˆ™ä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®
try:
    import dashscope
    DASHSCOPE_AVAILABLE = True
except ImportError:
    DASHSCOPE_AVAILABLE = False
    print("âš ï¸  DashScopeæœªå®‰è£…ï¼Œå°†ä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®è¿›è¡Œå­¦ä¹ ")

class EmbeddingDemo:
    """EmbeddingåŸºç¡€æ¼”ç¤ºç±»"""
    
    def __init__(self):
        """åˆå§‹åŒ–"""
        load_dotenv()
        self.api_key = os.getenv('DASHSCOPE_API_KEY')
        
        if DASHSCOPE_AVAILABLE and self.api_key:
            dashscope.api_key = self.api_key
            self.use_real_api = True
            print("âœ… ä½¿ç”¨çœŸå®APIè¿›è¡Œembedding")
        else:
            self.use_real_api = False
            print("ğŸ”§ ä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®è¿›è¡Œå­¦ä¹ ï¼ˆé€‚åˆç¦»çº¿ç»ƒä¹ ï¼‰")
    
    def get_embedding(self, text: str) -> List[float]:
        """è·å–æ–‡æœ¬çš„å‘é‡è¡¨ç¤º
        
        Args:
            text: è¾“å…¥æ–‡æœ¬
            
        Returns:
            å‘é‡åˆ—è¡¨
        """
        if self.use_real_api:
            try:
                response = dashscope.TextEmbedding.call(
                    model=dashscope.TextEmbedding.Models.text_embedding_v1,
                    input=text
                )
                
                if response.status_code == 200:
                    return response.output['embeddings'][0]['embedding']
                else:
                    print(f"âŒ APIè°ƒç”¨å¤±è´¥: {response.message}")
                    return self._get_mock_embedding(text)
            except Exception as e:
                print(f"âŒ APIè°ƒç”¨å¼‚å¸¸: {str(e)}")
                return self._get_mock_embedding(text)
        else:
            return self._get_mock_embedding(text)
    
    def _get_mock_embedding(self, text: str) -> List[float]:
        """ç”Ÿæˆæ¨¡æ‹Ÿçš„embeddingå‘é‡ï¼ˆç”¨äºå­¦ä¹ å’Œæµ‹è¯•ï¼‰
        
        Args:
            text: è¾“å…¥æ–‡æœ¬
            
        Returns:
            æ¨¡æ‹Ÿçš„1536ç»´å‘é‡
        """
        # ä½¿ç”¨æ–‡æœ¬hashä½œä¸ºéšæœºç§å­ï¼Œç¡®ä¿ç›¸åŒæ–‡æœ¬å¾—åˆ°ç›¸åŒå‘é‡
        np.random.seed(hash(text) % (2**32))
        
        # ç”Ÿæˆ1536ç»´çš„éšæœºå‘é‡ï¼ˆä¸é€šä¹‰åƒé—®embeddingç»´åº¦ä¸€è‡´ï¼‰
        vector = np.random.normal(0, 1, 1536)
        
        # å½’ä¸€åŒ–å‘é‡
        vector = vector / np.linalg.norm(vector)
        
        return vector.tolist()
    
    def cosine_similarity(self, vec1: List[float], vec2: List[float]) -> float:
        """è®¡ç®—ä¸¤ä¸ªå‘é‡çš„ä½™å¼¦ç›¸ä¼¼åº¦
        
        Args:
            vec1: å‘é‡1
            vec2: å‘é‡2
            
        Returns:
            ç›¸ä¼¼åº¦åˆ†æ•° (-1åˆ°1ä¹‹é—´)
        """
        # è½¬æ¢ä¸ºnumpyæ•°ç»„
        v1 = np.array(vec1)
        v2 = np.array(vec2)
        
        # è®¡ç®—ä½™å¼¦ç›¸ä¼¼åº¦
        dot_product = np.dot(v1, v2)
        norm_v1 = np.linalg.norm(v1)
        norm_v2 = np.linalg.norm(v2)
        
        if norm_v1 == 0 or norm_v2 == 0:
            return 0.0
        
        return dot_product / (norm_v1 * norm_v2)
    
    def find_most_similar(self, query: str, documents: List[str]) -> Tuple[str, float]:
        """åœ¨æ–‡æ¡£åˆ—è¡¨ä¸­æ‰¾åˆ°ä¸æŸ¥è¯¢æœ€ç›¸ä¼¼çš„æ–‡æ¡£
        
        Args:
            query: æŸ¥è¯¢æ–‡æœ¬
            documents: æ–‡æ¡£åˆ—è¡¨
            
        Returns:
            (æœ€ç›¸ä¼¼çš„æ–‡æ¡£, ç›¸ä¼¼åº¦åˆ†æ•°)
        """
        query_embedding = self.get_embedding(query)
        
        best_doc = ""
        best_score = -1.0
        
        print(f"\nğŸ” æŸ¥è¯¢: '{query}'")
        print("ğŸ“Š ç›¸ä¼¼åº¦åˆ†æ:")
        
        for doc in documents:
            doc_embedding = self.get_embedding(doc)
            similarity = self.cosine_similarity(query_embedding, doc_embedding)
            
            print(f"  ğŸ“„ '{doc}' -> ç›¸ä¼¼åº¦: {similarity:.4f}")
            
            if similarity > best_score:
                best_score = similarity
                best_doc = doc
        
        return best_doc, best_score

def main():
    """ä¸»å‡½æ•° - æ¼”ç¤ºembeddingçš„åŸºæœ¬ç”¨æ³•"""
    print("ğŸš€ Day 1: EmbeddingåŸºç¡€å®æˆ˜")
    print("=" * 50)
    
    # åˆ›å»ºæ¼”ç¤ºå®ä¾‹
    demo = EmbeddingDemo()
    
    # 1. åŸºç¡€embeddingæ¼”ç¤º
    print("\nğŸ“ 1. åŸºç¡€æ–‡æœ¬å‘é‡åŒ–æ¼”ç¤º")
    text = "äººå·¥æ™ºèƒ½æ˜¯æœªæ¥çš„å‘å±•æ–¹å‘"
    embedding = demo.get_embedding(text)
    print(f"æ–‡æœ¬: '{text}'")
    print(f"å‘é‡ç»´åº¦: {len(embedding)}")
    print(f"å‘é‡å‰5ä¸ªå€¼: {embedding[:5]}")
    
    # 2. ç›¸ä¼¼åº¦è®¡ç®—æ¼”ç¤º
    print("\nğŸ”¢ 2. æ–‡æœ¬ç›¸ä¼¼åº¦è®¡ç®—æ¼”ç¤º")
    texts = [
        "äººå·¥æ™ºèƒ½æŠ€æœ¯å‘å±•è¿…é€Ÿ",
        "AIæŠ€æœ¯æ­£åœ¨å¿«é€Ÿè¿›æ­¥",
        "ä»Šå¤©å¤©æ°”å¾ˆå¥½",
        "æœºå™¨å­¦ä¹ æ˜¯AIçš„é‡è¦åˆ†æ”¯"
    ]
    
    embeddings = [demo.get_embedding(text) for text in texts]
    
    print("\nç›¸ä¼¼åº¦çŸ©é˜µ:")
    for i, text1 in enumerate(texts):
        for j, text2 in enumerate(texts):
            if i <= j:  # åªæ˜¾ç¤ºä¸Šä¸‰è§’çŸ©é˜µ
                similarity = demo.cosine_similarity(embeddings[i], embeddings[j])
                print(f"'{text1}' <-> '{text2}': {similarity:.4f}")
    
    # 3. è¯­ä¹‰æœç´¢æ¼”ç¤º
    print("\nğŸ” 3. ç®€å•è¯­ä¹‰æœç´¢æ¼”ç¤º")
    documents = [
        "Pythonæ˜¯ä¸€ç§æµè¡Œçš„ç¼–ç¨‹è¯­è¨€",
        "æœºå™¨å­¦ä¹ ç®—æ³•å¯ä»¥ä»æ•°æ®ä¸­å­¦ä¹ æ¨¡å¼",
        "æ·±åº¦å­¦ä¹ æ˜¯æœºå™¨å­¦ä¹ çš„ä¸€ä¸ªå­é¢†åŸŸ",
        "è‡ªç„¶è¯­è¨€å¤„ç†å¸®åŠ©è®¡ç®—æœºç†è§£äººç±»è¯­è¨€",
        "è®¡ç®—æœºè§†è§‰è®©æœºå™¨èƒ½å¤Ÿç†è§£å›¾åƒ",
        "ä»Šå¤©çš„åˆé¤å¾ˆç¾å‘³"
    ]
    
    queries = [
        "ä»€ä¹ˆæ˜¯æœºå™¨å­¦ä¹ ï¼Ÿ",
        "ç¼–ç¨‹è¯­è¨€æœ‰å“ªäº›ï¼Ÿ",
        "å¦‚ä½•å¤„ç†æ–‡æœ¬æ•°æ®ï¼Ÿ"
    ]
    
    for query in queries:
        best_doc, score = demo.find_most_similar(query, documents)
        print(f"\nâœ¨ æœ€ä½³åŒ¹é…: '{best_doc}' (ç›¸ä¼¼åº¦: {score:.4f})")
    
    print("\nğŸ‰ Day 1 å­¦ä¹ å®Œæˆï¼")
    print("\nğŸ“š ä»Šæ—¥å­¦ä¹ è¦ç‚¹:")
    print("1. âœ… æ–‡æœ¬å¯ä»¥è½¬æ¢ä¸ºé«˜ç»´å‘é‡è¡¨ç¤º")
    print("2. âœ… ç›¸ä¼¼çš„æ–‡æœ¬åœ¨å‘é‡ç©ºé—´ä¸­è·ç¦»æ›´è¿‘")
    print("3. âœ… ä½™å¼¦ç›¸ä¼¼åº¦æ˜¯è¡¡é‡æ–‡æœ¬ç›¸ä¼¼æ€§çš„å¸¸ç”¨æ–¹æ³•")
    print("4. âœ… Embeddingæ˜¯RAGç³»ç»Ÿçš„åŸºç¡€ç»„ä»¶")
    
    print("\nğŸ”— ä¸‹ä¸€æ­¥å­¦ä¹ :")
    print("- Day 2: å‘é‡æ•°æ®åº“(FAISS)çš„ä½¿ç”¨")
    print("- å­¦ä¹ å¦‚ä½•é«˜æ•ˆå­˜å‚¨å’Œæ£€ç´¢å¤§é‡å‘é‡")

if __name__ == "__main__":
    main()